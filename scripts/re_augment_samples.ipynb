{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "272099"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH_TO_SAMPLE_FILE = \"/home/chendian/CDConfusor/exp/data/cn/Wang271k/dcn_train.tsv\"\n",
    "lines = [line for line in open(PATH_TO_SAMPLE_FILE, 'r')]\n",
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 281381/281381 [00:04<00:00, 60302.75it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "char_level_pairs = []\n",
    "\n",
    "for line in tqdm(lines):\n",
    "    err, cor = line.rstrip().split('\\t')[:2]\n",
    "    err = err.replace(' ', '')\n",
    "    cor = cor.replace(' ', '')\n",
    "    if err == cor:\n",
    "        continue\n",
    "    else:\n",
    "        faulty_position = []\n",
    "        for i, (_e, _c) in enumerate(zip(err, cor)):\n",
    "            if _e != _c:\n",
    "                char_level_pairs.append((_e, _c))\n",
    "\n",
    "\n",
    "ct = Counter(char_level_pairs).most_common()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## char-level confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "char-cfs Loaded ['形近', '近音', '同部首同笔画']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "272099it [00:03, 72901.51it/s]\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "\n",
    "# char-level confusion from SpellGCN\n",
    "cfs_path = '../data/spellGraphs.txt'\n",
    "char_cfs = {}\n",
    "for line in open(cfs_path, 'r'):\n",
    "    l, r, t = line.strip().split('|')\n",
    "    if t in ['同音同调', '同音异调', '近音异调', '近音同调']:\n",
    "        t = '近音'\n",
    "    char_cfs.setdefault(t, {})\n",
    "    char_cfs[t].setdefault(l, [])\n",
    "    char_cfs[t][l].append(r)\n",
    "backup_cfs = deepcopy(char_cfs)\n",
    "print(\"char-cfs Loaded\", list(char_cfs.keys()))\n",
    "\n",
    "\n",
    "def char_confusor(char):\n",
    "    # always take different token\n",
    "    take = char\n",
    "    candidates = char_cfs['近音'].get(char, [char])\n",
    "    if candidates:\n",
    "        take = random.choice(candidates)\n",
    "        if take != char:\n",
    "            char_cfs['近音'][char].remove(take)\n",
    "    else:\n",
    "        if backup_cfs['近音'][char]:\n",
    "            char_cfs['近音'][char] = [_c for _c in backup_cfs['近音'][char]]\n",
    "    return take\n",
    "\n",
    "\n",
    "def augment_single_sample(err, cor, confusor):\n",
    "    faulty_position = []\n",
    "    for i, (_e, _c) in enumerate(zip(err, cor)):\n",
    "        if _e != _c:\n",
    "            faulty_position.append((i, _e, _c))\n",
    "    for i, e, c in faulty_position:\n",
    "        assert cor[i] == c\n",
    "        cor = f\"{cor[:i]}{confusor(c)}{cor[i+1:]}\"\n",
    "    return cor\n",
    "\n",
    "dir_path = '../exp/data/cn/'\n",
    "# SIGHAN\n",
    "# src_path = dir_path + 'sighan15/sighan15_train.tsv'\n",
    "# tgt_path = dir_path + 'sighan15/sighan15_train.augc.tsv'\n",
    "\n",
    "# Wang271K + SIGHAN\n",
    "src_path = dir_path + 'Wang271k/dcn_train.tsv'\n",
    "tgt_path = dir_path + 'Wang271k/dcn_train.augc.tsv'\n",
    "with open(tgt_path, 'w') as f:\n",
    "    for line in tqdm(open(src_path, 'r')):\n",
    "        err, cor = line.strip().split('\\t')\n",
    "        aug_err = augment_single_sample(err, cor, confusor=char_confusor)\n",
    "        if len(err) == len(cor):\n",
    "            f.write(f\"{aug_err}\\t{cor}\\n\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## word-level confusion\n",
    "> version 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# ime = json.load(open('../data/input_candidates.google.json', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 364 items from /home/chendian/CDConfusor//data/red_cache.pkl\n",
      "Loaded 186258 items from /home/chendian/CDConfusor//data/cfs_cache.pkl\n",
      "Loading is_memory.json (153.94MB) cost 5.083 seconds.\n",
      "Loaded 178481 items from /home/chendian/CDConfusor//data/is_memory.json\n",
      "Loading ime_memory.json (4647.33MB) cost 432.553 seconds.\n",
      "Loaded 190194 items from /home/chendian/CDConfusor//data/ime_memory.json\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import json\n",
    "import jieba\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "from pypinyin import lazy_pinyin\n",
    "\n",
    "mapping = {}\n",
    "used_conf = {}\n",
    "\n",
    "\"\"\"\n",
    "from src.confusor import Confusor as ConfusorV1\n",
    "conf = ConfusorV1(\n",
    "    cand_pinyin_num=10, \n",
    "    cos_threshold=(0., .75), \n",
    "    method='all-similar single-freedom', \n",
    "    token_sample_mode='sort', \n",
    "    pinyin_sample_mode='sort',  # special\n",
    "    weight=[1., 0, .2],   # pinyin score, similarity score, word freq score, IME ranking\n",
    "    conf_size=300, ime_weight=1,\n",
    "    debug=False)\n",
    "conf.conf_with_scores = True\n",
    "\"\"\"\n",
    "\n",
    "from src.confusor_v2 import Confusor as ConfusorV2\n",
    "cfs = ConfusorV2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: [('紧急', '0'),\n",
       "  ('禁忌', '1'),\n",
       "  ('晋级', '2'),\n",
       "  ('谨记', '3'),\n",
       "  ('金鸡', '4'),\n",
       "  ('近几', '5'),\n",
       "  ('近畿', '6'),\n",
       "  ('进即', '7-0'),\n",
       "  ('进急', '7-1'),\n",
       "  ('进几', '7-2'),\n",
       "  ('进及', '7-3'),\n",
       "  ('进机', '7-4'),\n",
       "  ('进级', '7-5'),\n",
       "  ('进记', '7-6'),\n",
       "  ('进集', '7-7'),\n",
       "  ('进既', '7-8'),\n",
       "  ('进鸡', '7-9'),\n",
       "  ('进寄', '7-10'),\n",
       "  ('进极', '7-11'),\n",
       "  ('进吉', '7-12'),\n",
       "  ('进己', '7-13'),\n",
       "  ('进基', '7-14'),\n",
       "  ('进挤', '7-15'),\n",
       "  ('进季', '7-16'),\n",
       "  ('进计', '7-17'),\n",
       "  ('进剂', '7-18'),\n",
       "  ('进继', '7-19'),\n",
       "  ('金即', '8-0'),\n",
       "  ('金急', '8-1'),\n",
       "  ('金几', '8-2'),\n",
       "  ('金及', '8-3'),\n",
       "  ('金机', '8-4'),\n",
       "  ('金级', '8-5'),\n",
       "  ('金记', '8-6'),\n",
       "  ('金集', '8-7'),\n",
       "  ('金既', '8-8'),\n",
       "  ('金鸡', '8-9'),\n",
       "  ('金寄', '8-10'),\n",
       "  ('金极', '8-11'),\n",
       "  ('金吉', '8-12'),\n",
       "  ('金己', '8-13'),\n",
       "  ('金基', '8-14'),\n",
       "  ('金挤', '8-15'),\n",
       "  ('金季', '8-16'),\n",
       "  ('金计', '8-17'),\n",
       "  ('金剂', '8-18'),\n",
       "  ('金继', '8-19'),\n",
       "  ('近即', '9-0'),\n",
       "  ('近急', '9-1'),\n",
       "  ('近几', '9-2'),\n",
       "  ('近及', '9-3'),\n",
       "  ('近机', '9-4'),\n",
       "  ('近级', '9-5'),\n",
       "  ('近记', '9-6'),\n",
       "  ('近集', '9-7'),\n",
       "  ('近既', '9-8'),\n",
       "  ('近鸡', '9-9'),\n",
       "  ('近寄', '9-10'),\n",
       "  ('近极', '9-11'),\n",
       "  ('近吉', '9-12'),\n",
       "  ('近己', '9-13'),\n",
       "  ('近基', '9-14'),\n",
       "  ('近挤', '9-15'),\n",
       "  ('近季', '9-16'),\n",
       "  ('近计', '9-17'),\n",
       "  ('近剂', '9-18'),\n",
       "  ('近继', '9-19'),\n",
       "  ('尽即', '10-0'),\n",
       "  ('尽急', '10-1'),\n",
       "  ('尽几', '10-2'),\n",
       "  ('尽及', '10-3'),\n",
       "  ('尽机', '10-4'),\n",
       "  ('尽级', '10-5'),\n",
       "  ('尽记', '10-6'),\n",
       "  ('尽集', '10-7'),\n",
       "  ('尽既', '10-8'),\n",
       "  ('尽鸡', '10-9'),\n",
       "  ('尽寄', '10-10'),\n",
       "  ('尽极', '10-11'),\n",
       "  ('尽吉', '10-12'),\n",
       "  ('尽己', '10-13'),\n",
       "  ('尽基', '10-14'),\n",
       "  ('尽挤', '10-15'),\n",
       "  ('尽季', '10-16'),\n",
       "  ('尽计', '10-17'),\n",
       "  ('尽剂', '10-18'),\n",
       "  ('尽继', '10-19'),\n",
       "  ('紧即', '11-0'),\n",
       "  ('紧急', '11-1'),\n",
       "  ('紧几', '11-2'),\n",
       "  ('紧及', '11-3'),\n",
       "  ('紧机', '11-4'),\n",
       "  ('紧级', '11-5'),\n",
       "  ('紧记', '11-6'),\n",
       "  ('紧集', '11-7'),\n",
       "  ('紧既', '11-8'),\n",
       "  ('紧鸡', '11-9'),\n",
       "  ('紧寄', '11-10'),\n",
       "  ('紧极', '11-11'),\n",
       "  ('紧吉', '11-12'),\n",
       "  ('紧己', '11-13'),\n",
       "  ('紧基', '11-14'),\n",
       "  ('紧挤', '11-15'),\n",
       "  ('紧季', '11-16'),\n",
       "  ('紧计', '11-17'),\n",
       "  ('紧剂', '11-18'),\n",
       "  ('紧继', '11-19'),\n",
       "  ('仅即', '12-0'),\n",
       "  ('仅急', '12-1'),\n",
       "  ('仅几', '12-2'),\n",
       "  ('仅及', '12-3'),\n",
       "  ('仅机', '12-4'),\n",
       "  ('仅级', '12-5'),\n",
       "  ('仅记', '12-6'),\n",
       "  ('仅集', '12-7'),\n",
       "  ('仅既', '12-8'),\n",
       "  ('仅鸡', '12-9'),\n",
       "  ('仅寄', '12-10'),\n",
       "  ('仅极', '12-11'),\n",
       "  ('仅吉', '12-12'),\n",
       "  ('仅己', '12-13'),\n",
       "  ('仅基', '12-14'),\n",
       "  ('仅挤', '12-15'),\n",
       "  ('仅季', '12-16'),\n",
       "  ('仅计', '12-17'),\n",
       "  ('仅剂', '12-18'),\n",
       "  ('仅继', '12-19'),\n",
       "  ('今即', '13-0'),\n",
       "  ('今急', '13-1'),\n",
       "  ('今几', '13-2'),\n",
       "  ('今及', '13-3'),\n",
       "  ('今机', '13-4'),\n",
       "  ('今级', '13-5'),\n",
       "  ('今记', '13-6'),\n",
       "  ('今集', '13-7'),\n",
       "  ('今既', '13-8'),\n",
       "  ('今鸡', '13-9'),\n",
       "  ('今寄', '13-10'),\n",
       "  ('今极', '13-11'),\n",
       "  ('今吉', '13-12'),\n",
       "  ('今己', '13-13'),\n",
       "  ('今基', '13-14'),\n",
       "  ('今挤', '13-15'),\n",
       "  ('今季', '13-16'),\n",
       "  ('今计', '13-17'),\n",
       "  ('今剂', '13-18'),\n",
       "  ('今继', '13-19'),\n",
       "  ('斤即', '14-0'),\n",
       "  ('斤急', '14-1'),\n",
       "  ('斤几', '14-2'),\n",
       "  ('斤及', '14-3'),\n",
       "  ('斤机', '14-4'),\n",
       "  ('斤级', '14-5'),\n",
       "  ('斤记', '14-6'),\n",
       "  ('斤集', '14-7'),\n",
       "  ('斤既', '14-8'),\n",
       "  ('斤鸡', '14-9'),\n",
       "  ('斤寄', '14-10'),\n",
       "  ('斤极', '14-11'),\n",
       "  ('斤吉', '14-12'),\n",
       "  ('斤己', '14-13'),\n",
       "  ('斤基', '14-14'),\n",
       "  ('斤挤', '14-15'),\n",
       "  ('斤季', '14-16'),\n",
       "  ('斤计', '14-17'),\n",
       "  ('斤剂', '14-18'),\n",
       "  ('斤继', '14-19'),\n",
       "  ('劲即', '15-0'),\n",
       "  ('劲急', '15-1'),\n",
       "  ('劲几', '15-2'),\n",
       "  ('劲及', '15-3'),\n",
       "  ('劲机', '15-4'),\n",
       "  ('劲级', '15-5'),\n",
       "  ('劲记', '15-6'),\n",
       "  ('劲集', '15-7'),\n",
       "  ('劲既', '15-8'),\n",
       "  ('劲鸡', '15-9'),\n",
       "  ('劲寄', '15-10'),\n",
       "  ('劲极', '15-11'),\n",
       "  ('劲吉', '15-12'),\n",
       "  ('劲己', '15-13'),\n",
       "  ('劲基', '15-14'),\n",
       "  ('劲挤', '15-15'),\n",
       "  ('劲季', '15-16'),\n",
       "  ('劲计', '15-17'),\n",
       "  ('劲剂', '15-18'),\n",
       "  ('劲继', '15-19'),\n",
       "  ('锦即', '16-0'),\n",
       "  ('锦急', '16-1'),\n",
       "  ('锦几', '16-2'),\n",
       "  ('锦及', '16-3'),\n",
       "  ('锦机', '16-4'),\n",
       "  ('锦级', '16-5'),\n",
       "  ('锦记', '16-6'),\n",
       "  ('锦集', '16-7'),\n",
       "  ('锦既', '16-8'),\n",
       "  ('锦鸡', '16-9'),\n",
       "  ('锦寄', '16-10'),\n",
       "  ('锦极', '16-11'),\n",
       "  ('锦吉', '16-12'),\n",
       "  ('锦己', '16-13'),\n",
       "  ('锦基', '16-14'),\n",
       "  ('锦挤', '16-15'),\n",
       "  ('锦季', '16-16'),\n",
       "  ('锦计', '16-17'),\n",
       "  ('锦剂', '16-18'),\n",
       "  ('锦继', '16-19'),\n",
       "  ('禁即', '17-0'),\n",
       "  ('禁急', '17-1'),\n",
       "  ('禁几', '17-2'),\n",
       "  ('禁及', '17-3'),\n",
       "  ('禁机', '17-4'),\n",
       "  ('禁级', '17-5'),\n",
       "  ('禁记', '17-6'),\n",
       "  ('禁集', '17-7'),\n",
       "  ('禁既', '17-8'),\n",
       "  ('禁鸡', '17-9'),\n",
       "  ('禁寄', '17-10'),\n",
       "  ('禁极', '17-11'),\n",
       "  ('禁吉', '17-12'),\n",
       "  ('禁己', '17-13'),\n",
       "  ('禁基', '17-14'),\n",
       "  ('禁挤', '17-15'),\n",
       "  ('禁季', '17-16'),\n",
       "  ('禁计', '17-17'),\n",
       "  ('禁剂', '17-18'),\n",
       "  ('禁继', '17-19'),\n",
       "  ('晋即', '18-0'),\n",
       "  ('晋急', '18-1'),\n",
       "  ('晋几', '18-2'),\n",
       "  ('晋及', '18-3'),\n",
       "  ('晋机', '18-4'),\n",
       "  ('晋级', '18-5'),\n",
       "  ('晋记', '18-6'),\n",
       "  ('晋集', '18-7'),\n",
       "  ('晋既', '18-8'),\n",
       "  ('晋鸡', '18-9'),\n",
       "  ('晋寄', '18-10'),\n",
       "  ('晋极', '18-11'),\n",
       "  ('晋吉', '18-12'),\n",
       "  ('晋己', '18-13'),\n",
       "  ('晋基', '18-14'),\n",
       "  ('晋挤', '18-15'),\n",
       "  ('晋季', '18-16'),\n",
       "  ('晋计', '18-17'),\n",
       "  ('晋剂', '18-18'),\n",
       "  ('晋继', '18-19'),\n",
       "  ('筋即', '19-0'),\n",
       "  ('筋急', '19-1'),\n",
       "  ('筋几', '19-2'),\n",
       "  ('筋及', '19-3'),\n",
       "  ('筋机', '19-4'),\n",
       "  ('筋级', '19-5'),\n",
       "  ('筋记', '19-6'),\n",
       "  ('筋集', '19-7'),\n",
       "  ('筋既', '19-8'),\n",
       "  ('筋鸡', '19-9'),\n",
       "  ('筋寄', '19-10'),\n",
       "  ('筋极', '19-11'),\n",
       "  ('筋吉', '19-12'),\n",
       "  ('筋己', '19-13'),\n",
       "  ('筋基', '19-14'),\n",
       "  ('筋挤', '19-15'),\n",
       "  ('筋季', '19-16'),\n",
       "  ('筋计', '19-17'),\n",
       "  ('筋剂', '19-18'),\n",
       "  ('筋继', '19-19')]}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for item in cfs.confusor_cache['jinji'].values():\n",
    "    for k, v in item:\n",
    "        print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['紧急',\n",
       " '解决',\n",
       " '仅仅',\n",
       " '禁忌',\n",
       " '经济',\n",
       " '晋级',\n",
       " '积极',\n",
       " '紧紧',\n",
       " '谨记',\n",
       " '姐姐',\n",
       " '金鸡',\n",
       " '进军',\n",
       " '近几',\n",
       " '拒绝',\n",
       " '锦江',\n",
       " '近畿',\n",
       " '接近',\n",
       " '进即',\n",
       " '金价',\n",
       " '进急',\n",
       " '金即',\n",
       " '究竟',\n",
       " '晋江',\n",
       " '进几',\n",
       " '金急',\n",
       " '近即',\n",
       " '基金',\n",
       " '进价']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[k # (k, round(v, 3)) \n",
    " for k, v in cfs('紧急', return_score=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_confusor(word, random_select=True):\n",
    "    if word not in used_conf or len(used_conf.get(word, [])) == 0:\n",
    "        used_conf[word] = [] \n",
    "        res = conf(word)\n",
    "        min_score = min([x[1] for x in res])\n",
    "        for w, score in res:\n",
    "            used_conf[word].extend([w] * int((score - min_score) // 0.01 + 1))\n",
    "        mapping[word] = [w for w in used_conf[word]]\n",
    "    \"\"\"\n",
    "    elif len(used_conf[word]) == 0:  # all out\n",
    "        if word in mapping:\n",
    "            used_conf[word] = mapping[word]\n",
    "    \"\"\"\n",
    "    if word in used_conf[word]:\n",
    "        used_conf[word].remove(word)\n",
    "    if random_select:\n",
    "        ret = random.choice(used_conf[word])\n",
    "        used_conf[word].remove(ret)\n",
    "    else:\n",
    "        ret = used_conf[word][0]\n",
    "        used_conf[word] = used_conf[word][1:]\n",
    "    return ret\n",
    "\n",
    "\n",
    "def word_confusor_ime(word, random_select=True):\n",
    "    py_case = lazy_pinyin(word)\n",
    "    complete_input_sequence = ''.join(py_case)\n",
    "    if word not in used_conf or len(used_conf.get(word, [])) == 0:\n",
    "        used_conf[word] = [] \n",
    "        res = []\n",
    "        for omission in range(1, len(py_case[-1])):\n",
    "            inp_seq = complete_input_sequence[:-omission]\n",
    "            if inp_seq not in ime:\n",
    "                print(f\"{inp_seq} not in IME Records.\")\n",
    "            candidates = ime[inp_seq]\n",
    "            res.extend([(c, 1 / (idx + 1)) for idx, c in enumerate(candidates) if len(c) <= len(word)])\n",
    "        for w, score in res:\n",
    "            used_conf[word].extend([w] * int(score // 0.01 + 1))\n",
    "        if len(used_conf[word]) == 0:\n",
    "            return word_confusor(word, random_select=random_select)\n",
    "    if word in used_conf[word]:\n",
    "        used_conf[word].remove(word)\n",
    "    if random_select:\n",
    "        ret = random.choice(used_conf[word])\n",
    "        used_conf[word].remove(ret)\n",
    "        if len(ret) < len(word):\n",
    "            return ret + word_confusor_ime(\n",
    "                word[len(ret):], random_select=random_select)\n",
    "    else:\n",
    "        ret = used_conf[word][0]\n",
    "        used_conf[word] = used_conf[word][1:]\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def word_confusor_cfs(word, random_select=True, ignore_word=None):\n",
    "    if word not in used_conf or len(used_conf.get(word, [])) == 0:\n",
    "        used_conf[word] = [] \n",
    "        res = []\n",
    "        \n",
    "        candidates = cfs(word, return_score=True)\n",
    "        # print(candidates)\n",
    "        res.extend(\n",
    "            [(c, score) for idx, (c, score) in enumerate(candidates) \n",
    "             if len(c) == len(word)])\n",
    "\n",
    "        for w, score in res:\n",
    "            used_conf[word].extend([w] * int( (1. - score) ** 2 // 0.01 + 1))\n",
    "    \n",
    "    if word in used_conf[word]:\n",
    "        used_conf[word].remove(word)\n",
    "    if ignore_word is not None:\n",
    "        if ignore_word in used_conf[word]:\n",
    "            used_conf[word].remove(ignore_word)\n",
    "\n",
    "    if len(used_conf[word]) == 0:\n",
    "        try:  # sample single char in it.\n",
    "            char = random.choice(word)\n",
    "            _c = word_confusor_cfs(char, random_select=True)\n",
    "            ret = ''.join([_c if c == char else c for c in word])\n",
    "            return ret\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            return word\n",
    "\n",
    "    if random_select:\n",
    "        ret = random.choice(used_conf[word])\n",
    "        used_conf[word].remove(ret)\n",
    "    else:\n",
    "        ret = used_conf[word][0]\n",
    "        used_conf[word] = used_conf[word][1:]\n",
    "\n",
    "    return ret\n",
    "\n",
    "\n",
    "def augment_single_sample(err, cor, confusor):\n",
    "    faulty_position = []\n",
    "    for i, (_e, _c) in enumerate(zip(err, cor)):\n",
    "        if _e != _c:\n",
    "            faulty_position.append((i, _e, _c))\n",
    "    es, cs, streak = \"\", \"\", []\n",
    "    for i, e, c in faulty_position:\n",
    "        assert cor[i] == c\n",
    "        if len(streak) == 0:\n",
    "            es, cs, streak = e, c, [i]\n",
    "        elif i == streak[-1]+1:\n",
    "            es += e\n",
    "            cs += c\n",
    "            streak.append(i)\n",
    "        elif i != streak[-1] + 1 and len(cs) > 0:\n",
    "            cor = f\"{cor[:streak[0]]}{confusor(cs)}{cor[streak[-1]+1:]}\"\n",
    "            es, cs, streak = e, c, [i]\n",
    "    else:\n",
    "        if len(cs) > 0:\n",
    "            cor = f\"{cor[:streak[0]]}{confusor(cs)}{cor[streak[-1]+1:]}\"\n",
    "            es, cs, streak = \"\", \"\", []\n",
    "    return cor\n",
    "\n",
    "import Pinyin2Hanzi \n",
    "def augment_single_sample_jieba(err, cor, confusor):\n",
    "    faulty_position = []\n",
    "    words = jieba.lcut(err)\n",
    "    pivot = 0\n",
    "    for i, w in enumerate(words):\n",
    "        _e = err[pivot: pivot+len(w)]\n",
    "        _c = cor[pivot: pivot+len(w)]\n",
    "        if Pinyin2Hanzi.is_chinese(_e) and _e != _c:\n",
    "            if len(_e) > 2:\n",
    "                for offset, (__e, __c) in enumerate(zip(_e, _c)):\n",
    "                    if __e != __c:\n",
    "                        faulty_position.append(\n",
    "                            (pivot+offset, pivot+offset+1, __e, __c))\n",
    "            else:\n",
    "                faulty_position.append((pivot, pivot+len(w), _e, _c))\n",
    "        pivot += len(w)\n",
    "    for i, j, _, c in faulty_position:\n",
    "        try:\n",
    "            assert c == cor[i:j]\n",
    "            # not the same with current error\n",
    "            changed_word = confusor(c, ignore_word=err[i:j])  \n",
    "            cor = f\"{cor[:i]}{changed_word}{cor[j:]}\"\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(cor, cor[i:j])\n",
    "    return cor\n",
    "\n",
    "\n",
    "same, faulty = 0, 0\n",
    "src_path = '../exp/data/tmp/findoc_train.230329.augw2.tsv'\n",
    "tgt_path = '../exp/data/tmp/findoc_train.230329.augw3.tsv'\n",
    "\n",
    "\n",
    "with open(tgt_path, 'w') as f:\n",
    "    for idx, line in tqdm(enumerate(open(src_path, 'r'))):\n",
    "        err, cor = line.strip().split('\\t')\n",
    "        # aug_err = augment_single_sample(err, cor, confusor=word_confusor)\n",
    "        aug_err = augment_single_sample_jieba(\n",
    "            err, cor, confusor=word_confusor_cfs)\n",
    "        if len(aug_err) == len(cor):\n",
    "            f.write(f\"{aug_err}\\t{cor}\\n\")\n",
    "            if aug_err == cor:\n",
    "                same += 1\n",
    "            else:\n",
    "                f.write(f\"{cor}\\t{cor}\\n\")\n",
    "                faulty += 1\n",
    "        else:\n",
    "            print(len(aug_err), aug_err)\n",
    "            print(len(cor), cor)\n",
    "            print(same, faulty)\n",
    "\n",
    "same, faulty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfs.ism.ime_memory['hutao']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfs.ism.save_memory()\n",
    "cfs.ism.update_memory_from_tmp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 804M\n",
      "-rw-rw-r-- 1 chendian chendian 650M Mar 23 23:41 ime_memory.json\n",
      "-rw-rw-r-- 1 chendian chendian 154M Mar 22 19:05 memory.json\n"
     ]
    }
   ],
   "source": [
    "!ls -lht /data/chendian/CDConfusor/tmp/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['--',\n",
       " '27632',\n",
       " '常',\n",
       " '被',\n",
       " '用来',\n",
       " '进行',\n",
       " '稀释',\n",
       " '血管',\n",
       " '中',\n",
       " '血液',\n",
       " '的',\n",
       " '实验',\n",
       " '，',\n",
       " '可能',\n",
       " '有助于',\n",
       " '研发',\n",
       " '高血压',\n",
       " '治疗剂',\n",
       " '。']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jieba\n",
    "jieba.lcut(\"--27632常被用来进行稀释血管中血液的实验，可能有助于研发高血压治疗剂。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(158432, 113667)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "same, faulty"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Confusion\n",
    "> Version 2.0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bbcm",
   "language": "python",
   "name": "bbcm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
