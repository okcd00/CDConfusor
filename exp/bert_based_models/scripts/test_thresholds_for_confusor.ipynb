{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use beam method.\n",
      "Pinyin sampling mode: special.\n",
      "Token sampling mode: sort.\n",
      "Now loading pinyin2token corpus.\n",
      "Now loading zi_sim_matrix.\n",
      "Now loading REDscore.\n",
      "Now generating score matrix.\n",
      "Load word freuency data.\n"
     ]
    }
   ],
   "source": [
    "import sys \n",
    "sys.path.append('/home/chendian/BBCM/')\n",
    "from bbcm.data.loaders.confusor import *\n",
    "conf = Confusor(cos_threshold=(0.1, 0.5), method='beam', token_sample_mode='sort', \n",
    "                pinyin_sample_mode='special', weight=[1, 0.3, 1], debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0e-1 ['宅圈:2', '债全:1', '宰圈:2', '在全:2', '在泉:2', '再全:2', '仔犬:2', '再圈:2', '栽拳:2', '再权:2']\n",
      "1e-1 ['债全:1', '宅圈:2', '宰圈:2', '在全:2', '载权:2', '再圈:2', '载铨:2', '赵权:2', '再权:2', '仔犬:2']\n",
      "2e-1 ['债全:1', '宅圈:2', '在全:2', '宰圈:2', '赵权:2', '载权:2', '再圈:2', '载铨:2', '债钱:1', '再权:2']\n",
      "3e-1 ['债全:1', '宅圈:2', '在全:2', '赵权:2', '宰圈:2', '债钱:1', '载权:2', '再圈:2', '载铨:2', '债欠:1']\n",
      "4e-1 ['债全:1', '宅圈:2', '在全:2', '赵权:2', '债钱:1', '宰圈:2', '载权:2', '债欠:1', '再圈:2', '载铨:2']\n",
      "5e-1 ['债全:1', '在全:2', '赵权:2', '债钱:1', '宅圈:2', '债算:1', '债欠:1', '宰圈:2', '载权:2', '再圈:2']\n",
      "6e-1 ['债全:1', '在全:2', '债钱:1', '赵权:2', '债算:1', '宅圈:2', '债欠:1', '宰圈:2', '载权:2', '再圈:2']\n",
      "7e-1 ['债全:1', '债钱:1', '在全:2', '赵权:2', '债算:1', '债欠:1', '宅圈:2', '载权:2', '宰圈:2', '再圈:2']\n",
      "8e-1 ['债全:1', '债钱:1', '在全:2', '赵权:2', '债算:1', '债欠:1', '载权:2', '窄缘:2', '宅圈:2', '宰圈:2']\n",
      "9e-1 ['债全:1', '债钱:1', '在全:2', '赵权:2', '债算:1', '债欠:1', '窄缘:2', '载权:2', '宰圈:2', '宅院:2']\n"
     ]
    }
   ],
   "source": [
    "tw = '债券'\n",
    "conf.method = ''\n",
    "for w in range(10):\n",
    "    conf.weight = [1, 0.1 * w, 1]\n",
    "    confusion_set = conf(tw)\n",
    "    print(f\"{w}e-1\", [f\"{c}:{sum([c[i]!=_w for i, _w in enumerate(tw)])}\" for c in confusion_set])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init indexing ends in 0.0005736351013183594 seconds\n",
      "Loaded 958 files from /data/chendian/clean_pretrain_data_test.\n"
     ]
    }
   ],
   "source": [
    "from bbcm.data.datasets.csc import PureTextDataset\n",
    "fp = \"/data/chendian/clean_pretrain_data_test\"\n",
    "dataset = PureTextDataset(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use beam method.\n",
      "Pinyin sampling mode: special.\n",
      "Token sampling mode: sort.\n",
      "Now loading pinyin2token corpus.\n",
      "Now loading zi_sim_matrix.\n",
      "Now loading REDscore.\n",
      "Now generating score matrix.\n",
      "Load word freuency data.\n",
      "Dynamic Data Collator Init\n",
      "with 5.0% faulty positions.\n",
      "Now loading NER model from /home/chendian/download/stanford-corenlp-4.2.2/\n"
     ]
    }
   ],
   "source": [
    "from tools.train_csc import DynamicDataCollatorForCsc, BertTokenizer, get_abs_path\n",
    "\n",
    "from bbcm.config import cfg\n",
    "config_file = \"fin/b_findoc_pret_test.yml\"\n",
    "if os.path.exists(config_file):\n",
    "    cfg.merge_from_file(config_file)\n",
    "else:\n",
    "    cfg.merge_from_file(get_abs_path('configs', config_file))\n",
    "tokenizer = BertTokenizer.from_pretrained(cfg.MODEL.BERT_CKPT)\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(cfg.MODEL.BERT_CKPT)\n",
    "col_fn_train = DynamicDataCollatorForCsc(tokenizer=tokenizer, augmentation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24588it [46:50, 10.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected an invalid text: K 为特征因子，K=∑𝑖=1，k∈[-0.25,0.25]。\n",
      "Failed for counting words\n",
      "{(14,), (15,), (0,), (25, 26, 27, 28), (5, 6), (2,), (29,), (16, 17, 18, 19, 20, 21, 22, 23), (30,), (7,), (13,), (24,), (3, 4), (8, 9, 10, 11, 12)}\n",
      "[0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [30] 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24622it [46:54,  7.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected an invalid text: 险最低资本计算公式𝑀𝐶人身险利率=Max[（AA 基础情景– PV 基础情景)－（AA 不利情景–PV 不利情景)，0]可知，当保持资产和负债的高度匹配时，资产和负债的利率敏感性才会高度一致，𝑀𝐶人身险利率才会降低。\n",
      "Failed for counting words\n",
      "{(111,), (54, 55), (59,), (74, 75), (86, 87), (5, 6), (23,), (36, 37), (61,), (97,), (46, 47), (98, 99, 100, 101), (95, 96), (78,), (16, 17), (80, 81), (64,), (91,), (1,), (76, 77), (19, 20, 21), (41,), (102, 103, 104), (56, 57), (70,), (108,), (3, 4), (18,), (27, 28), (58,), (85,), (22,), (60,), (29, 30), (68, 69), (50, 51, 52), (93, 94), (73,), (9, 10), (88, 89, 90), (105, 106), (62, 63), (66, 67), (11, 12), (43, 44), (83, 84), (33, 34), (48, 49), (79,), (0,), (38, 39), (65,), (92,), (109, 110), (2,), (40,), (24, 25), (31,), (42,), (107,), (71, 72), (82,), (13, 14, 15), (7, 8)}\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0] [108] 103\n",
      "Failed for counting words\n",
      "{(111,), (54, 55), (59,), (74, 75), (86, 87), (5, 6), (23,), (36, 37), (61,), (97,), (46, 47), (98, 99, 100, 101), (95, 96), (78,), (16, 17), (80, 81), (64,), (91,), (1,), (76, 77), (19, 20, 21), (41,), (102, 103, 104), (56, 57), (70,), (108,), (3, 4), (18,), (27, 28), (58,), (85,), (22,), (60,), (29, 30), (68, 69), (50, 51, 52), (93, 94), (73,), (9, 10), (88, 89, 90), (105, 106), (62, 63), (66, 67), (11, 12), (43, 44), (83, 84), (33, 34), (48, 49), (79,), (0,), (38, 39), (65,), (92,), (109, 110), (2,), (40,), (24, 25), (31,), (42,), (107,), (71, 72), (82,), (13, 14, 15), (7, 8)}\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0] [109, 110] 104\n",
      "Failed for counting words\n",
      "{(111,), (54, 55), (59,), (74, 75), (86, 87), (5, 6), (23,), (36, 37), (61,), (97,), (46, 47), (98, 99, 100, 101), (95, 96), (78,), (16, 17), (80, 81), (64,), (91,), (1,), (76, 77), (19, 20, 21), (41,), (102, 103, 104), (56, 57), (70,), (108,), (3, 4), (18,), (27, 28), (58,), (85,), (22,), (60,), (29, 30), (68, 69), (50, 51, 52), (93, 94), (73,), (9, 10), (88, 89, 90), (105, 106), (62, 63), (66, 67), (11, 12), (43, 44), (83, 84), (33, 34), (48, 49), (79,), (0,), (38, 39), (65,), (92,), (109, 110), (2,), (40,), (24, 25), (31,), (42,), (107,), (71, 72), (82,), (13, 14, 15), (7, 8)}\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0] [111] 106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "61080it [1:51:52,  9.10it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid index 958 with offset 61080",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_41081/3526410934.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mchanged_chars_in_word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrong_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     o_text, c_text, current_wids, detail_dict = col_fn_train.sample_augment_single(\n",
      "\u001b[0;32m~/.conda/envs/bbcm/lib/python3.7/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1185\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1186\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/BBCM/bbcm/data/datasets/csc.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mfile_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_search_file_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfile_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Invalid index {file_index} with offset {index}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfile_index\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_file_index\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfile_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid index 958 with offset 61080"
     ]
    }
   ],
   "source": [
    "from bbcm.data.loaders.collator import *\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "changed_chars_in_word = defaultdict(int)\n",
    "selected_word_length = defaultdict(int)\n",
    "for i, sample in tqdm(enumerate(dataset)):\n",
    "    ot, ct, wrong_id = sample\n",
    "    o_text, c_text, current_wids, detail_dict = col_fn_train.sample_augment_single(\n",
    "        ot, ct, wrong_id, valid_position_mask=True, \n",
    "        random_pos=True, word_level=True, detail=True)\n",
    "    word_offsets = detail_dict['word_offsets']\n",
    "    # inv_dict = {tuple(v): k for k, v in word_offsets.items()}\n",
    "    for word_index, count in Counter([word_offsets.get(cw, [cw])[0] \n",
    "        for cw in current_wids]).most_common():\n",
    "        changed_chars_in_word[count] += 1\n",
    "        selected_word_length[len(word_offsets.get(word_index, [word_index]))] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int, {1: 84926, 2: 23491, 3: 2241, 4: 89})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "changed_chars_in_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7556517dc383211685f710d8044246aff26e1405386725c85667dcb59239ebb1"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
